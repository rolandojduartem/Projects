class_mode = "binary"
)
test_auggen <- flow_images_from_directory(
test_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
train_auggen <- flow_images_from_directory(
train_dir,
datagen,
target_size = c(150, 150),
batch_size = 32,
class_mode = "binary"
)
valid_auggen <- flow_images_from_directory(
valid_dir,
valid_datagen,
target_size = c(150, 150),
batch_size = 32,
class_mode = "binary"
)
test_auggen <- flow_images_from_directory(
test_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 32,
class_mode = "binary"
)
rm(model_aug)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
epochs = 100,
batch_size = 32,
validation_data = valid_auggen,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
epochs = 100,
validation_data = valid_auggen,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100
epochs = 100,
validation_data = valid_auggen,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
callbacks = callbacks_list)
rm(model_aug)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
length(train_auggen)
length(train_auggen[0])
length(train_auggen[1])
length(train_auggen[2])
length(train_auggen[3])
train_auggen$index_array
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 1000,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 50,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
rm(model_aug)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 31,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 10,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 10,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 10,
callbacks = callbacks_list)
rm(model_aug)
k_clear_session()
train_auggen <- flow_images_from_directory(
train_dir,
datagen,
target_size = c(150, 150),
batch_size = 1,
class_mode = "binary"
)
valid_auggen <- flow_images_from_directory(
valid_dir,
valid_datagen,
target_size = c(150, 150),
batch_size = 1,
class_mode = "binary"
)
test_auggen <- flow_images_from_directory(
test_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 1,
class_mode = "binary"
)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 10,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 10,
callbacks = callbacks_list)
rm(model_aug)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 10,
callbacks = callbacks_list)
train_auggen <- flow_images_from_directory(
train_dir,
datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
valid_auggen <- flow_images_from_directory(
valid_dir,
valid_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
test_auggen <- flow_images_from_directory(
test_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 10,
callbacks = callbacks_list)
rm(model_aug)
k_clear_session()
#Creating new model
model_aug <- keras_model_sequential()%>%
layer_conv_2d(32, c(3, 3), activation = "relu", input_shape = c(150, 150, 3))%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(64, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_conv_2d(128, c(3, 3), activation = "relu")%>%
layer_max_pooling_2d(c(2, 2))%>%
layer_flatten()%>%
layer_dense(512, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
summary(model_aug)
#Compiling new model
model_aug %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc"))
#Creating callbacks
callbacks_list = list(callback_early_stopping(patience = 10,
restore_best_weights = T),
callback_model_checkpoint("best_aug_modelR.h5",
save_best_only = T))
#Fitting model
history <- model_aug %>% fit_generator(train_auggen,
steps_per_epoch = 100,
epochs = 100,
validation_data = valid_auggen,
validation_steps = 50,
callbacks = callbacks_list)
View(train_auggen)
plot(history)
best_model_aug <- load_model_hdf5("best_aug_modelR.h5")
best_model_aug %>% evaluate(test_auggen)
best_model_aug %>% evaluate_generator(test_auggen, steps = 50)
model %>% load_model_hdf5("modelR.h5")
model <- load_model_hdf5("modelR.h5")
model %>% evaluate_generator(test_generator, steps = 50)
#Classifer dogs and cats usin CNN transfering learning
#It is the same problem as Classifier_dogs_and_cats.R, but, using transfering learning to achieve more accuracy.
#Importing libraries and generating dataset
require(keras)
train_dir <- file.path("./train")
valid_dir <- file.path("./validation")
test_dir <- file.path("./test")
datagen_train <- image_data_generator(
rescale = 1 / 255,
rotation_range = 40,
width_shift_range = 0.2,
height_shift_range = 0.2,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = T,
fill_mode = "nearest"
)
datagen_valid <- image_data_generator(
rescale = 1 / 255
)
datagen_test <- image_data_generator(
rescale = 1 / 255
)
generator_train <- flow_images_from_directory(
train_dir,
datagen_train,
target_size = c(250, 250),
batch_size = 16,
class_mode = "binary"
)
generator_valid <- flow_images_from_directory(
valid_dir,
datagen_valid,
target_size = c(250, 250),
batch_size = 16,
class_mode = "binary"
)
generator_test <- flow_images_from_directory(
test_dir,
datagen_test,
target_size = c(250, 250),
batch_size = 16,
class_mode = "binary"
)
#VGG16
conv_base <- application_vgg16(
weights = "imagenet",
include_top = F,
input_shape = c(150, 150, 3)
)
#VGG16
conv_base <- application_vgg16(
weights = "imagenet",
include_top = F,
input_shape = c(150, 150, 3)
)
model_vgg <- keras_model_sequential()%>%
conv_base%>%
layer_flatten()%>%
layer_dense(256, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
model
model_vgg
model_vgg %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_adam(lr = 2e-5),
metrics = list("acc"))
cb_list = list(callback_early_stopping(patience = 25,
restore_best_weights = T),
callback_model_checkpoint("best_vgg16R.h5"))
freeze_weights(conv_base)
model_vgg
history_vgg <- model_vgg %>% fit_generator(generator_train, epoch = 1000,
validation_data = generator_valid,
callbacks = cb_list)
history_vgg <- model_vgg %>% fit_generator(generator_train, epoch = 1000,
validation_data = generator_valid,
callbacks = cb_list,
steps_per_epoch = 100,
validation_steps = 50)
generator_train <- flow_images_from_directory(
train_dir,
datagen_train,
target_size = c(250, 250),
batch_size = 20,
class_mode = "binary"
)
generator_valid <- flow_images_from_directory(
valid_dir,
datagen_valid,
target_size = c(250, 250),
batch_size = 20,
class_mode = "binary"
)
generator_test <- flow_images_from_directory(
test_dir,
datagen_test,
target_size = c(250, 250),
batch_size = 20,
class_mode = "binary"
)
rm(model_vgg)
k_clear_session()
#VGG16
conv_base <- application_vgg16(
weights = "imagenet",
include_top = F,
input_shape = c(150, 150, 3)
)
model_vgg <- keras_model_sequential()%>%
conv_base%>%
layer_flatten()%>%
layer_dense(256, activation = "relu")%>%
layer_dense(1, activation = "sigmoid")
model_vgg
model_vgg %>% compile(loss = "binary_crossentropy",
optimizer = optimizer_adam(lr = 2e-5),
metrics = list("acc"))
cb_list = list(callback_early_stopping(patience = 25,
restore_best_weights = T),
callback_model_checkpoint("best_vgg16R.h5"))
freeze_weights(conv_base) #Avoid train weights from vgg convolutional base
history_vgg <- model_vgg %>% fit_generator(generator_train, epoch = 1000,
validation_data = generator_valid,
callbacks = cb_list,
steps_per_epoch = 100,
validation_steps = 50)
source('C:/Users/Rolando/Workspace/Machine Learning/Projects/CNN_dogs_and_cats_classifier/R/Using_transfer_learning.R', echo=TRUE)
